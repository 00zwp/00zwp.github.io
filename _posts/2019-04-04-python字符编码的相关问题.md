---
layout:     post
title:      python字符编码的相关问题
subtitle:    ""
date:       2019-04-04
author:     tianhaoo
header-img: img/post-bg/30.jpg
catalog: true
tags:
  - python
---

## 背景

### 前辈的话
> 一旦走上了编程之路，如果你不把编码问题搞清楚，那么它一定会像幽灵一般纠缠着你整个职业生涯，各种灵异事件会接踵而来，挥之不去。只有发挥程序员死磕到底的精神你才有可能彻底摆脱编码问题带来的烦恼。


### 所有的编码方式

随着计算机的发展，我们在中文环境下能遇到的编码方式大概有以下几种：

1. `ASCII`只有英文字母、数字和符号等
2. `GB2312`包含ASCII，还有全部的汉字
3. `GBK`在GB2312的基础上增加了藏文等字符
4. `ANSI` 在简体中文系统下，ANSI 编码代表 GB2312 编码，在日文操作系统下，ANSI 编码代表 JIS 编码，具体代表哪种取决于系统默认的编码方式
5. `Unicode`包含所有的字符编码，但体积比较大
6. `UTF-8`压缩版的Unicode，类似霍夫曼编码的方式（概率大的码长短）

然而无论怎么编码，我们的目的只有一个，那就是把非数字的文本存到计算机里去。我们知道计算机只能存储二进制的数据（也就是0和1）以上几种不同的编码方式
只是意味着映射的关系不同例如在ASCII中十进制数字65（也就是二进制的1000001）代表字母A，而在Unicode中则对应着一个另一个完全不同的字符。

总之，**编码方式是文本与二进制数据之间的一种对应规则**。

## 编码带来的困惑

根据前面的分析，不同的字符集有不同的编码方式，不同的操作系统，不同的文本编辑器都会使用不同的编码方式，这下简直乱了套了，那么操作系统和编辑器是怎么解决这个问题的呢？

### 操作系统的角度

作为操作系统，有责任将文件系统中每一个完好的文件正确的解码显示出来，但操作系统只能看到磁盘上面`010101011`这种二进制数据。那么这个文件是使用何种编码方式进行编码的？不同的文件类型有不同的方法：

#### 字节序标记BOM
有的文件使用“字节序标记BOM” (Byte Order Mark)，也就是放置于编码字节序列开始处的一段特殊字节序列，用于表示文本序列的大小端序。当操作系统看到后缀名是`.xxx`的时候，就会先去读前几个字节，确定文件是使用何种编码方式进行编码的，然后后面的内容都是用这种方式进行解码，这样文档的内容就可以正确的显示出来了。

这本来是很好的方法，但不符合Linux&Unix系的设计理念，因为字节标记序那一段内容是对用户不可见的，但Linux&Unix觉得任何文件内容都应该是可编辑的，所以在linux系统中很少见到使用BOM的方法。

类似WINDOWS自带的记事本等软件，在保存一个以UTF-8编码的文件时，会在文件开始的地方插入三个不可见的字符（0xEF 0xBB 0xBF，即BOM）。它是一串隐藏的字符，用于让记事本等编辑器识别这个文件是否以UTF-8编码。对于一般的文件，这样并不会产生什么麻烦。但有些情况下，BOM是个大麻烦，它会将前面几个字符当成是文本内容进行读取，造成意料之外的后果。

#### 其他方式进行标记

实际上有些程序无法使用BOM的标记方式，例如PHP文件，如果用记事本打开一个.php文件，没问题，正常显示，但是再用php.exe去解析这个.php文件的时候就报了错。因为我们知道php文件开头必须有`<?php`的字样，但是记事本在打开该文件后往开头插入了BOM标记，但php解释器对这一点并不知情，所以造成了错误。

在python2中则是使用了另一种更好的方法：在python源文件的开头加上`#coding=utf-8`之类的标记，[官网](https://www.python.org/dev/peps/pep-0263/)的介绍是这样的：
> This PEP proposes to introduce a syntax to declare the encoding of a Python source file. The encoding information is then used by the Python parser to interpret the file using the given encoding. Most notably this enhances the interpretation of Unicode literals in the source code and makes it possible to write Unicode literals using e.g. UTF-8 directly in an Unicode aware editor.
也就是说python2使用这种方式来声明Python2源文件的编码，然后Python解析器将会这个编码信息来使用给定的编码解释文件。

而在python3中，python脚本文件是默认使用UTF-8的方式进行编码和解码的，除非使用另外的编码方式，否则不用特别声明编码方式。

#### 使用默认的编码方式

如果操作系统在面对一个二进制文件时，没有任何明确的信息告诉操作系统这一堆二进制数字是使用何种编码方式进行编码的，而这个文件的后缀名（Windows下）又明确的告诉操作系统这是一个文本文件，用户需要打开它。那么操作系统只好先看看文本编辑器的默认编码方式，像记事本的话默认是ANSI的（在中国的话也就是GB2312)，那就使用ANSI进行解码，如果文本编辑器也没有指定编码方式，那就使用系统默认的编码方式进行解码。

实际上，绝大多数编码问题也都是出现在这里，如果这个未知编码方式的文本的解码方式跟编码方式不一致，那么必然会有乱码的情况出现，如果二者的编码方式是包含的关系（像UTF-8与ASCII)，那么就会出现部分乱码，也就是经常出现的打开一个文件，英文正常显示，中文全是乱码。

### 文本编辑器的角度

这里说的是广义上的文本编辑器，不仅仅包括记事本、VS code等，包括python、C语言等所有能往磁盘上写文本文件的程序都在我们的讨论范围之内。

#### 常规的文本编辑器

作为一个合格的文本编辑器，以记事本为例，作为一个拥有图形化界面，旨在帮助用户更方便的编辑并保存文本文件的应用程序，文本编辑器有责任使用一定的方法让自己所编辑保存的文本文件能够被操作系统识别并正确地打开。

### 其他文件的编码规则

说了这么多文本文件的编码方式，其实对于非文本而言，也是有一套固定的规则进行解码的，比如图片、视频、音频文件，而这些只需要根据后缀名就可以判断使用何种方式进行读取和解码，例如.jpeg格式和.bmp格式的图片各自有相应的解码规则，改一下后缀名后操作系统便无法读取。这让我回想起几周前学院的csteaching网站面临的一次恶意攻击，一个用户在实验报告平台上上传了一段代码和一个txt文件，这个txt文件用记事本打开显示的是一堆乱码，显然这要么是解码文本的方式不对，要么这根本就不是个文本文件。在尝试使用二进制编辑器打开该文件后，发现开头几个二进制字节是`89 50 4E 47 0D 0A 1A 0A`（16进制），[上网搜索](https://www.filesignatures.net/index.php?page=search&search=89504E470D0A1A0A&mode=SIG)后发现这是PNG的文件格式，然后将该文件放入虚拟机中文件名改成.png，刚改完这边windows defender就报“发现恶意软件，正在删除”，双击打开后发现是一张模糊的二次元人物图像，但该文件有700多k大，照理说不会像现在一样这么糊，我们推断其中应该有隐藏的恶意代码，经过一番探究发现是一个老掉牙的web shell攻击`China Chopper`,又名[中国菜刀](https://en.wikipedia.org/wiki/China_Chopper)，fireeye上面给了详细的[介绍](https://www.fireeye.com/blog/threat-research/2013/08/breaking-down-the-china-chopper-web-shell-part-i.html)，（不知道我们学院的实验报告网站有什么好黑的）。扯远了...总之这个例子告诉我们，理解掌握文件的编码非常重要。

### python中的编码

*在python3中，字符串是以UTF-8的方式进行编码的*

这意味着两点：
1. python的字符串定义的时候，可以使用任意国家的语言，比如 str="(括号里的是阿拉伯语)"
2. 字符串在存储的时候


