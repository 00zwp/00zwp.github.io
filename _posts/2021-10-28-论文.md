---
layout: post
title: Paper-FDA Federated Defense Against Adversarial Attacks for Cloud-Based IIoT Applications
subtitle: ""
data: 2021-10-28
author: Fat-Pman
header-img: img/post-bg/50.jpg
catalog: true
tags: Papers
---
<script type="/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

### FDA: Federated Defense Against Adversarial Attacks for Cloud-Based IIoT Applications

（这里的对抗攻击都有哪儿些，还是原来的中毒攻击？ -基于数据 Or -基于模型）

#### Abstract

在AI与IoT技术普及下，对抗攻击激增，用于欺骗IIoT应用的深度神经网络。由于偏见的训练数据以及脆弱的潜层（underlying models）模型，对输入的微弱修改足以带来破坏性的结果。虽然，已有的方法在防御恶意攻击上很有前景，但他们大多数只能应对有限的一直攻击类型，这对大规模IIoT的发展是个巨大挑战。为了解决这个问题，我们提出了一个有效的联邦防御方法（FDA3），它能够聚合不同来源对抗样本提供的防御信息。受到联邦学习的启发，我们提出的基于云端的架构能够在工业互联网设备间对多种攻击，实现防御共享。实验结构表明，利用我们方法生成的DNNs，相较于已存在的特定攻击的对抗训练<font color=red>（FGSM IBM）</font>，不仅能够抵御更多恶意攻击，而且能够防御IIoT上的新攻击。

<font color=red>文章中为什么把对抗样本的存在归因于偏见的训练数据以及脆弱的潜层</font>

#### introduction

深度学习(DL)技术越来越多地应用于安全关键信息物理系统(CPS)和物联网(IoT)领域，如自动驾驶、商业监控和机器人等，这些领域输入的预测正确性至关重要。然而，随着IIoT(IIoT)应用的蓬勃发展，它们不可避免地成为恶意对手<font color=blue>[5]、[6]</font>的主要攻击目标。无论对抗性的攻击是有意还是无意，由于训练数据的偏见或过拟合模型，轻微的修改输入往往会使脆弱的物联网应用程序表现出不正确或意外的行为，这可能导致严重的后果。

[^-^]:
    需要看一看这篇论文引用的攻击方法是什么？cites:[5-6]

大多数现有的对抗式攻击专注于生成具有扰动的IIoT输入（对抗样本），以愚弄DNNs这种对抗样本能误导分类器产生错误预测，同时这些扰动无法被人眼察觉。目前提出了许多防御方法来抵抗这些攻击，例如ensemble diversity[8], PuVAE[9],adversarial training。然而，它们中大多数并不适合IIoT应用。主要因为:1)大多数防御方法都只防御一种特定类型的攻击;(2)IIoT应用通常分散在不同的地方，面临各种对抗性攻击。在这种情况下，同一类型的IIoT设备应配置不同的DNNs，以适应不同的环境。当各种新的对抗性攻击出现时，情况变得更糟，因为IIoT设计人员很难快速找到新的解决方案来防御此类攻击。

作为一种分布式机器学习方法，联邦学习(FL)[10]能够在IIoT设备上的大量分散数据上训练高质量的集中化模型。它已经被广泛研究并应用于，解决基于云架构的隐私、所有权和数据位置等基本问题。同时在云架构中，参与设备数量巨大，但互联网连接缓慢或不可靠。基于联邦平均技术[11]，FL允许在不暴露存储在IIoT设备上的数据的情况下训练DNN。新DNN的权重在云中使用FL合成，用于构建一个全局模型，然后推回不同的IIoT设备进行预测。然而，到目前为止，没有一种现有的基于fl的方法研究对IIoT应用的对抗攻击的防御。

由于云架构可以通过将物联网设备的部分计算任务卸载到远程云服务器，从而扩展物联网设备处理能力，云计算和物联网的结合正成为一种流行的范式，使大规模智能物联网应用成为可能。在CPS环境下，IIoT设备与云连接[12]。然而，无论云服务器的角色是否用于培训或推断，IIoT设备需要将原始数据发送到云服务器，其中网络延迟和数据隐私问题不容忽视。此外，如果IIoT应用的设备采用相同类型的DNNs，则对抗性攻击的多样性很容易破坏应用的健壮性。因此，如何为大量相同类型的IIoT设备生成健壮的DNN，同时又能保护这些设备的隐私，成为一个挑战。受联邦学习概念的启发，本文提出了一种适用于大规模IIoT应用的有效联邦防御框架FDA。它作出了以下三个主要贡献:
1）出了一种新的针对IIoT设备的<font color=blue>对抗训练损失函数</font>，充分考虑了对抗性攻击的多样性。
2)我们提出了一种有效的联邦对抗学习方案，该方案可以得到强壮的DNNs来抵抗广泛的对抗攻击。
3)在基于云架构的基础上，提出了一种面向大规模IIoT应用的新型联邦防御框架。

在两个著名的基准数据集上的实验结果表明，我们提出的方法在IIoT设备上生成的DNN比目前最先进的方法更能抵抗对抗性攻击。此外，所研究的IIoT应用规模越大<font color=blue>(是否可以理解为所能接受到的对抗样本信息越全面或者原始信息越多)</font>，生成的DNN的鲁棒性越好。本文的其余部分组织如下。第二部分介绍了基于dnn的物联网设计中对抗攻击防御机制的相关工作。第三节详细介绍了我们的联邦防御框架FDA。第四节给出了实验结果，展示了我们方法的有效性和可扩展性。最后，第五部分对全文进行总结。

#### Related Work
相关工作不展开介绍，主要提几点本人感兴趣的：
    1.生成物理的对抗样本欺骗模型——[15-16]
    2.介绍了3类防御算法：A-优化目标分类器的梯度<font color=blue>(这类防御没有接触过，可以看看-[8-9-22])</font>B-增加自动编码器C-对抗训练

#### 联邦防御方法
由于隐私信息泄露，攻击者可以从IIoT设备获取DNN模型信息进行攻击。在我们的方法中，在IIoT设备提供的隐私保护机制的帮助下，我们假设模型破解时间比模型更新周期长。在这种情况下，对手总是无法获得IIoT设备使用的模型的最新版本。然而，攻击者可以根据已获得的隐私数据，使用<font color=blue>传输攻击（transfer attack）</font>来欺骗DNN模型。本文主要研究如何对威胁模型进行再训练，使其能够抵抗由敌手产生的各种类型的对抗实例。以下小节将介绍我们基于云的联邦防御结构，对设备级别的联邦对抗训练损失函数，以及模型更新和同步细节。

##### FDA Architecture

![framwork](/img/20211028/1.png)

<font color=red>需要特别注意Nature Samples与Adversarial samples的工作，是在于损失函数吗？</font>

图1详细描述了FDA的框架及其工作流程，其灵感来自于对抗式训练和联合学习方法。我们方法的架构由两部分组成，即IIoT设备及其云服务器。除了预测功能外，存在于物联网设备中的DNN还负责抵御对抗样本的DNN更新。最初，所有设备共享相同的DNN。由于它们部署在不同的环境中，因此可能会遇到不同的输入示例和不同类型的攻击。这种不平衡使得联合学习成为聚合不同防御能力的最佳解决方案。

该云服务器由两个模块组成，即攻击监控模块和联邦防御模型生成模块。攻击监控模块,根据IIoT设备位置或类型，记录其最新的攻击信息。该模块管理了所有报告的攻击方案(即源代码或可执行程序)组成的库。这些信息可以由IIoT设备制造商或第三方机构收集。当攻击监控模块检测到设备受到新的攻击时，会要求设备下载相应的攻击方案，进行对抗训练。与联邦学习类似，联邦防御模型生成模块定期收集设备梯度信息并将其聚合，以获得具有更好鲁棒性的更新模型。然后，该模块将把新形成的模型发送到所有连接的IIoT设备，以实现模型同步。

在IIoT设备的执行过程中，该设备保持一个缓冲区，以保存一组随机收集的高预测置信度自然示例。在特定时期内，所有IIoT设备都需要通过联合学习方式进行重训练和同步。这个过程包括三个步骤。首先，根据云服务器分配的攻击方案，每个设备在本地生成对应的对抗样本，形成一个重训练集，重训练集的元素分别是自然样本和对应的对抗样本。在第二步中，本地对抗训练过程定期将IIoT设备最新获得的梯度信息上传到云服务器，用于模型更新和同步。最后，与联合学习类似，由我们的联合防御方法生成的模型将部署在每个连接的IIoT设备上。注意，当新的物联网设备加入IIoT应用程序时，需要从服务器下载新的模型。由于不同设备的多样性，新模型具有更强的鲁棒性，可以抵抗更多不同类型的攻击。由于云服务器与IIoT设备之间的交互只涉及到梯度信息，因此可以保证IIoT设备的数据私密性。

![question](/img/20211028/2.png)

##### Loss

在考虑对抗性攻击时，对抗性训练损失函数的定义与传统的损失函数的定义有所不同。现有的对抗训练损失函数大多由<font color=red>正常损失函数和对抗性损失函数[17]</font>两部分组成。它们可以表述为

$$
    \large{L(x,\widehat{x},y|\theta{})=(1-\alpha{})L_{normal}+{\alpha{}} L_{adv}(\widehat{x},y|\theta{})}
$$

${\large}L_{normal} (x,y|\theta)$表示正常损失函数，其中x，y表示自然(正态)样例和模型参数为$\theta$时的分类标签。α值越高，说明对抗性损失函数的权重越大，对整体损失函数的贡献越大。

对于不同的对抗攻击，存在不同的方法来获得最小${\large}L(x,\widehat{x},y|\theta)$的最优$\theta$。以$L_{\infty}$范数的FGSM攻击为例，可以利用下面的公式计算最有的$\theta$:

$$
\large{\theta{^*}=arg\underset{\theta{}}min \underset{x\subseteq{D}}E \left[\underset{||\widehat{x}-x||_\infty{\leq{\epsilon{}}}}{max} L(x,\widehat{x},y|\theta{}) \right]}
$$

![L_norm](/img/20211028/3.png)

为了将这个损失函数拓展到更多的范数类型，我们将损失函数扩展如下：

$$
\large{L_{fed}(x,\widehat{x},y|\theta{})=\frac{1}{N}{\sum{}}_{k=1} ^N L \left(x^k,\widehat{x}^k,y^k,\theta{}\right)}
$$

利用算数平均对每个终端设备的损失函数求平均得到全局模型的损失函数，从而找到最合适的参数$\theta$，满足下式：

$$
\large{\theta{^*}=arg\underset{\theta{}}{min}{\left\{  
\underset{x\subseteq{D},\widehat{x}\subseteq{D_{L\infty{}}}}{E}\left[\underset{||\widehat{x}-x||_\infty{}\leq{\epsilon{}}}{max}L_{fed}(x,\widehat{x},y|\theta{})\right]+\\
\underset{x\subseteq{D},\widehat{x}\subseteq{D_{L0}}}{E}\left[\underset{||\widehat{x}-x||_0\leq{\sigma{}}}{max}L_{fed}(x,\widehat{x},y|\theta{})\right]+\\
\underset{x\subseteq{D},\widehat{x}\subseteq{D_{L2}}}{E}\left[\underset{||\widehat{x}-x||_2\leq{\delta{}}}{max}L_{fed}(x,\widehat{x},y|\theta{})\right]+
\right\}}}
$$

##### Federated Defense Model Generation

联合防御方法由两部分组成，即IIoT设备和相应的云服务器。在执行过程中，IIoT设备随机收集一组高可信度的自然实例，并将它们保存在本地内存中。根据云服务器分配的攻击方案，IIoT设备生成对抗样本进行模型再训练。请注意，由于IIoT设备的资源有限(如内存大小、计算能力)，云服务器通常只分配有限数量的攻击方案给IIoT设备。与联合学习类似，我们的联合防御方法的对抗训练过程涉及多个epoch，其中一个epoch可能根据用户指定的批大小涉及多个迭代。在我们的方法中，我们考虑每个迭代为一轮，在一轮内，所有工业物联网设备将从其本地重新培训的模型获得的梯度信息发送到云服务器，然后云服务器将梯度聚合，并将更新后的模型与所有IIoT设备同步。



