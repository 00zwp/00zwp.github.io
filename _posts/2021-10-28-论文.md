---
layout: post
title: Paper-FDA Federated Defense Against Adversarial Attacks for Cloud-Based IIoT Applications
subtitle: ""
data: 2021-10-28
author: Fat-Pman
header-img: img/post-bg/50.jpg
catalog: true
tags: Papers
---

### FDA: Federated Defense Against Adversarial Attacks for Cloud-Based IIoT Applications

（这里的对抗攻击都有哪儿些，还是原来的中毒攻击？ -基于数据 Or -基于模型）

#### Abstract

在AI与IoT技术普及下，对抗攻击激增，用于欺骗工业物联网应用的深度神经网络。由于偏见的训练数据以及脆弱的潜层（underlying models）模型，对输入的微弱修改足以带来破坏性的结果。虽然，已有的方法在防御恶意攻击上很有前景，但他们大多数只能应对有限的一直攻击类型，这对大规模工业物联网的发展是个巨大挑战。为了解决这个问题，我们提出了一个有效的联邦防御方法（FDA3），它能够聚合不同来源对抗样本提供的防御信息。受到联邦学习的启发，我们提出的基于云端的架构能够在工业互联网设备间对多种攻击，实现防御共享。实验结构表明，利用我们方法生成的DNNs，相较于已存在的特定攻击的对抗训练（），不仅能够抵御更多恶意攻击，而且能够防御IIoT上的新攻击。

<font color=red>文章中为什么把对抗样本的存在归因于偏见的训练数据以及脆弱的潜层</font>

#### introduction

深度学习(DL)技术越来越多地应用于安全关键信息物理系统(CPS)和物联网(IoT)领域，如自动驾驶、商业监控和机器人等，这些领域输入的预测正确性至关重要。然而，随着工业物联网(IIoT)应用的蓬勃发展，它们不可避免地成为恶意对手<font color=blue>[5]、[6]</font>的主要攻击目标。无论对抗性的攻击是有意还是无意，由于训练数据的偏见或过拟合模型，轻微的修改输入往往会使脆弱的物联网应用程序表现出不正确或意外的行为，这可能导致严重的后果。

[^-^]:
    需要看一看这篇论文引用的攻击方法是什么？cites:[5-6]

大多数现有的对抗式攻击专注于产生具有扰动的工业物联网输入，这种攻击被命名为“对抗式示例”，以愚弄深度神经网络(DNNs)。这种对抗性的例子可能会误导分类器模型预测不正确的输出，而它们是无法被人眼识别的。为了抵抗这些攻击，提出了集成多样性、PuVAE和对抗性训练等多种防御方法。然而，它们中的大多数并不适合工业物联网应用。这主要是因为:1)大多数防御方法都只防御一种特定类型的攻击;(2)工业物联网应用通常分散在不同的地方，面临各种对抗性攻击。在这种情况下，同一类型的工业物联网设备应配置不同的dnn，以适应不同的环境。当各种新的对抗性攻击出现时，情况变得更糟，因为工业物联网设计人员很难快速找到新的解决方案来防御此类攻击

