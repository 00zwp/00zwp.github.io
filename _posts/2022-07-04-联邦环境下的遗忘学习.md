---
layout: post
title: 联邦环境下的遗忘学习
description: ""
subtitle: ""
data: 2022-07-4
author: Fat-Pman 
header-img: img/post-bg/28.jpg
catalog: true
tags: python federated-learning
---

#### 联邦环境下的遗忘学习

##### 为什么要在联邦学习环境下开展遗忘工作

    1. 与联邦学习自身期望/性质相关 - 联邦学习(FL)已经成为一种隐私感知的协作学习范式 - 也就是说在考虑联邦学习过程中，除去数据转移的难度，一个很大的原因就是隐私问题。

    2.遗忘属于客户的权利 客户可以根据自身的权利要求-撤走数据-并要求他们的数据在模型中无法体现-<font color=red>但是如何证明这其中的效果-遗忘效果</font>

    3.从攻击的角度出发-当原始数据中参杂了部分的威胁数据，需要保证这些数据的破坏性已经移除 -- <font color=blue>由于联邦学习的多协作模式，导致这部分威胁难以被发现</font>

##### 遗忘工作如何进行

<strong>遗忘工作的进行点--基本是在联邦学习聚合完成以后，由于训练的可覆盖性</strong>

<button>Check</button>

```
    FedEraser:通过改变重训练的起点-减少遗忘代价
    待总结
```

##### 如何证明是否有效被遗忘

大部分的现有工作都是通过 遗忘学习前后模型性能的变化 侧面验证遗忘的有效性 - (loos/accuracy在遗忘数据上) - (后门攻击的效果)
<p>
    后门攻击效果如下 r表示激活器
</p>

![后门攻击公式](./img/20220704/1.png)

<img src=./img/20220707/1.png>后门攻击效果</img>

同样也有使用模型权重的差异来衡量这一有效性

<font color=red><strong>可借鉴</strong></font>在VF一文中-借鉴了水印(watermarking)以及指纹（fingerprinting),链接如下：
<link href="https://arxiv.org/pdf/1701.04082.pdf">Embedding water-marks into deep neural networks</link>
<link href="https://arxiv.org/ftp/arxiv/papers/1905/1905.04519.pdf">Interpret federated learning with shapley values</link>
<link href="https://arxiv.org/pdf/1910.12903v1.pdf">Ipguard: Protecting the intellectual property of deep neural networks via fingerprinting the classification boundary</link>